{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "from functional import seq # for chaining filters and maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```\n",
    "interim/\n",
    "    aligned_data/\n",
    "        $part_id/\n",
    "            audio/\n",
    "            empatica/\n",
    "            edf/\n",
    "            chillp/\n",
    "            timeline.csv\n",
    "            metadata.json\n",
    "            markers.csv\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "raw_empatica_dir = Path('../../data/raw/uz_study/empatica_data/')\n",
    "edf_dir = Path('../../data/raw/uz_study/study_data/Physiological Data/Files/')\n",
    "raw_chillp_dir = Path('../../data/raw/uz_study/chillp_data/')\n",
    "aligned_data_dir = Path('../../data/interim/uz_study/aligned_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_mapping = pd.read_csv('../../data/interim/uz_study/aligned_data/mapped_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Empatica data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'context_aware'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-162b6a532e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcontext_aware\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempatica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me4_connect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mE4ConnectProcessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mE4ConnectProcessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'context_aware'"
     ]
    }
   ],
   "source": [
    "from context_aware.interfaces.empatica.e4_connect import E4ConnectProcessor\n",
    "proc = E4ConnectProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71e028704e44f18913658c44f2689fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'proc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6c04ea2cc1c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Put the data into the correct folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'directory_empatica'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     proc.process_unzipped_folder(folder_path=f'../../data/raw/uz_study/empatica_data/{row[\"directory_empatica\"]}', \n\u001b[0m\u001b[0;32m      4\u001b[0m                                  \u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf'../../data/interim/uz_study/aligned_data/{row[\"Participant\"]}/empatica/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                  save_type='feather')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'proc' is not defined"
     ]
    }
   ],
   "source": [
    "# Put the data into the correct folder\n",
    "for _, row in tqdm(df_mapping.dropna(subset=['directory_empatica']).iterrows()):\n",
    "    proc.process_unzipped_folder(folder_path=f'../../data/raw/uz_study/empatica_data/{row[\"directory_empatica\"]}', \n",
    "                                 save_dir=f'../../data/interim/uz_study/aligned_data/{row[\"Participant\"]}/empatica/', \n",
    "                                 save_type='feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## EDF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\mitch\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import neurokit2 as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_mapping['t_start_edf'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cbf9101dca47a48e33aac0918cc19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=58.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG_06 - Full (Raw).edf\n",
      "edf: EEG_06 - Full (Raw).edf\tpart id: 5\n",
      "edf time:2020-01-01 10:43:08 \t t_study: 2020-01-28 09:48:11.673000+01:00 \t old_marker: 2020-01-28 09:00:46.701172\n",
      "Converting \"time\" to \"<class 'numpy.int64'>\"...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-33c60fc795c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;31m# use neurokit to create an ecg and resp dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mdf_ecg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mecg_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_edf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ECG1+'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_edf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mdf_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsp_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_edf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'R+'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_edf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\neurokit2\\ecg\\ecg_process.py\u001b[0m in \u001b[0;36mecg_process\u001b[1;34m(ecg_signal, sampling_rate, method)\u001b[0m\n\u001b[0;32m     81\u001b[0m                                        \u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                                        \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                                        correct_artifacts=True)\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     rate = ecg_rate(rpeaks,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\neurokit2\\ecg\\ecg_peaks.py\u001b[0m in \u001b[0;36mecg_peaks\u001b[1;34m(ecg_cleaned, sampling_rate, method, correct_artifacts)\u001b[0m\n\u001b[0;32m     68\u001b[0m         _, rpeaks = ecg_fixpeaks(rpeaks,\n\u001b[0;32m     69\u001b[0m                                  \u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msampling_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                                  iterative=True)\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     instant_peaks = signal_formatpeaks(rpeaks,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\neurokit2\\ecg\\ecg_fixpeaks.py\u001b[0m in \u001b[0;36mecg_fixpeaks\u001b[1;34m(rpeaks, sampling_rate, iterative, show)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             artifacts, subspaces = _find_artifacts_lipponen2019(rpeaks_corrected,\n\u001b[1;32m---> 87\u001b[1;33m                                                                 sampling_rate)\n\u001b[0m\u001b[0;32m     88\u001b[0m             rpeaks_corrected = _fix_artifacts_lipponen2019(rpeaks_corrected,\n\u001b[0;32m     89\u001b[0m                                                            \u001b[0martifacts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\neurokit2\\ecg\\ecg_fixpeaks.py\u001b[0m in \u001b[0;36m_find_artifacts_lipponen2019\u001b[1;34m(rpeaks, sampling_rate)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mdrrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;31m# Normalize by threshold.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0mdrrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_threshold_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_half\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m# Pad drrs with one element.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\neurokit2\\ecg\\ecg_fixpeaks.py\u001b[0m in \u001b[0;36m_threshold_normalization\u001b[1;34m(data, alpha, window_half)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0mdata_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"reflect\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwh\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miqr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mwh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;31m# normalize data by threshold (remove padding)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mdata_th\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36miqr\u001b[1;34m(x, axis, rng, scale, nan_policy, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   2756\u001b[0m     \u001b[0mrng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2757\u001b[0m     pct = percentile_func(x, rng, axis=axis, interpolation=interpolation,\n\u001b[1;32m-> 2758\u001b[1;33m                           keepdims=keepdims, contains_nan=contains_nan)\n\u001b[0m\u001b[0;32m   2759\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m_iqr_percentile\u001b[1;34m(x, q, axis, interpolation, keepdims, contains_nan)\u001b[0m\n\u001b[0;32m   2908\u001b[0m         \u001b[1;31m# (`numpy.lib.function_base._ureduce` for the curious).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2909\u001b[0m         result = np.percentile(x, q, axis=axis, keepdims=keepdims,\n\u001b[1;32m-> 2910\u001b[1;33m                                interpolation=interpolation)\n\u001b[0m\u001b[0;32m   2911\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2912\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'linear'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpercentile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3704\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Percentiles must be in the range [0, 100]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3705\u001b[0m     return _quantile_unchecked(\n\u001b[1;32m-> 3706\u001b[1;33m         a, q, axis, out, overwrite_input, interpolation, keepdims)\n\u001b[0m\u001b[0;32m   3707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3824\u001b[0m     r, k = _ureduce(a, func=_quantile_ureduce_func, q=q, axis=axis, out=out,\n\u001b[0;32m   3825\u001b[0m                     \u001b[0moverwrite_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverwrite_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m                     interpolation=interpolation)\n\u001b[0m\u001b[0;32m   3827\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3401\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3403\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3404\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\EEGStudy2020\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, interpolation, keepdims)\u001b[0m\n\u001b[0;32m   3926\u001b[0m         \u001b[0mweights_above\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3928\u001b[1;33m         \u001b[0map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_below\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_above\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3930\u001b[0m         \u001b[1;31m# ensure axis with q-th is first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fs = 512 # all signals within the .edfs are sampled at 512Hz\n",
    "\n",
    "for edf_file in tqdm(sorted(list(edf_dir.glob('*Full*.edf')))):\n",
    "        # only retain the .edf files of which we have a mapping to the participant ID\n",
    "        edf_id = int(edf_file.name.split('EEG_')[1][:2])\n",
    "        if edf_id in df_mapping.edf_marker_id.dropna().values:\n",
    "            raw= mne.io.read_raw_edf(edf_file, verbose=False)\n",
    "            row = df_mapping[df_mapping.edf_marker_id == edf_id]\n",
    "            part_id = row['Participant'].values[0]\n",
    "            print(edf_file.name)\n",
    "            print(f'edf: {edf_file.name}\\tpart id: {part_id}')\n",
    "            print(f'edf time:{datetime.fromtimestamp(raw.annotations.orig_time)} \\t t_study: {row.t_study.iloc[0]} \\t old_marker: {row.old_marker_time.iloc[0]}')\n",
    "\n",
    "            # Assert that the trigger sequence is the same as in the corresponding eprime file\n",
    "            df_marker = pd.read_csv(aligned_data_dir.joinpath(str(part_id)).joinpath('marker.csv'))\n",
    "            low_range, high_range = list(range(1, 68)), list(range(68, 135))\n",
    "            edf_descr, marker_descr = seq(raw.annotations.description[2:]).map(int), seq(df_marker.Description.values)\n",
    "            assert edf_descr.filter(lambda x: x in low_range) == marker_descr.filter(lambda x: x in low_range)\n",
    "            assert edf_descr.filter(lambda x: x in high_range) == marker_descr.filter(lambda x: x in high_range)\n",
    "            \n",
    "            # set the correct time in the .edf files\n",
    "            # dus gewoon in de edf file de correcte date + timezone zeeten en gucci drippin' \n",
    "            df_edf = raw.to_data_frame() # \n",
    "            fs = 512\n",
    "            # TODO -> fix code here for common triggers ... \n",
    "            # of misschien te experiment end gebruiken voor alignment \n",
    "            \n",
    "#             def get_t_start_trigger(df_marker, raw, trigger):\n",
    "#                 marker_row = df_marker[df_marker.Description == trigger]\n",
    "#                 # print(marker_row)\n",
    "#                 onset = raw.annotations.onset[list(raw.annotations.description).index(str(trigger))]\n",
    "#                 assert len(marker_row) == 1 \n",
    "#                 assert int(onset) == marker_row.Position.values[0] // 512.0, print(f\"onset: {onset}, row position {row.Position.values[0]//512}\")\n",
    "#                 t_start = pd.to_datetime(marker_row['timestamp'], infer_datetime_format=True).iloc[-1] - timedelta(seconds=onset)\n",
    "#                 return t_start\n",
    "#             common_trigger = edf_descr.filter(lambda x: x in low_range)[0]  # define a common trigger whic will be used to set the correct date\n",
    "#             t_start = get_t_start_trigger(df_marker, raw, trigger=common_trigger)\n",
    "#                         print('mapped on common trigger   :', t_start)\n",
    "#             print('mapped on experiment start :', get_t_start_trigger(df_marker, raw, trigger=150))\n",
    "#             print('mapped on experiment end   :', get_t_start_trigger(df_marker, raw, trigger=151))\n",
    "#             print('mapped on Stress3 SAM start:', get_t_start_trigger(df_marker, raw, trigger=174))\n",
    "            t_start = pd.to_datetime(row['t_start_eprime'], infer_datetime_format=True).dt.tz_localize(None).iloc[-1]\n",
    "\n",
    "            df_edf.index = pd.date_range(start=t_start, tz=timezone('Europe/Brussels'), freq=f'{1e9/ fs}N', periods=len(df_edf))\n",
    "            df_mapping.at[df_mapping.Participant == part_id, 't_start_edf'] = t_start\n",
    "\n",
    "        # save the edf dataframe\n",
    "            save_dir = aligned_data_dir.joinpath(str(part_id)).joinpath('edf')\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            \n",
    "            # use neurokit to create an ecg and resp dataframe\n",
    "            df_ecg = nk.ecg_process(df_edf['ECG1+'].values, sampling_rate=fs)[0].set_index(df_edf.index)\n",
    "            df_resp = nk.rsp_process(df_edf['R+'].values, sampling_rate=fs)[0].set_index(df_edf.index)\n",
    "         \n",
    "            df_edf.reset_index(drop=False).rename(columns={'index': 'timestamp'}).to_feather(save_dir.joinpath('edf.feather'))\n",
    "            df_ecg.reset_index(drop=False).rename(columns={'index': 'timestamp'}).to_feather(save_dir.joinpath('ecg.feather'))\n",
    "            df_resp.reset_index(drop=False).rename(columns={'index': 'timestamp'}).to_feather(save_dir.joinpath('resp.feather'))\n",
    "\n",
    "df_mapping.to_csv('../../data/interim/uz_study/aligned_data/mapped_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Chill+ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "chillp_raw_dir = Path('../../../data/raw/uz_study/chillp_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 1\n",
      "skipping 61\n"
     ]
    }
   ],
   "source": [
    "for _, row in df_mapping.iterrows():\n",
    "    part_id = row['Participant']\n",
    "    chillp_data_dir = chillp_raw_dir.joinpath(str(part_id))\n",
    "    \n",
    "    if not aligned_data_dir.joinpath(str(part_id)).is_dir():\n",
    "        print(f'skipping {part_id}')\n",
    "        continue\n",
    "    \n",
    "    if chillp_data_dir.is_dir():\n",
    "        chillp_aligned_dir = aligned_data_dir.joinpath(str(part_id)).joinpath('chillp')\n",
    "        if not chillp_aligned_dir.is_dir():\n",
    "            os.makedirs(chillp_aligned_dir)\n",
    "        # iterate over all the feathers\n",
    "        for feather_file in chillp_data_dir.glob('*.feather'):\n",
    "            !cp -pr {str(feather_file)} {str(aligned_data_dir.joinpath(str(part_id)).joinpath('chillp')) + '/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Speech data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "audio_data_dir = Path('../../../data/raw/uz_study/study_data/Tablet\\ Data/Audio/')\n",
    "aligned_data_dir = Path('../../../data/interim/uz_study/aligned_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tablet_data_mapping = pd.read_csv('../../../data/raw/uz_study/study_data/Tablet Data/Behavioural/results_09_03_2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "> TODO: I assume that the id corresponds with participant id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# discard the invalid id's\n",
    "tablet_data_mapping = tablet_data_mapping[tablet_data_mapping['id'].map(int) < 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# perfect -> participant 25 & 45 hebben onafgewerkte data én zitten niet in de dataframe\n",
    "for _, row in tablet_data_mapping.iterrows():\n",
    "    part_id = row['id']\n",
    "    save_dir = aligned_data_dir.joinpath(str(part_id)).joinpath('audio/')\n",
    "    if not save_dir.is_dir():\n",
    "        os.makedirs(save_dir)\n",
    "    !cp -pr {str(audio_data_dir.joinpath(str(part_id))) + '/*'} {save_dir} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Questionnaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "TODO:\n",
    " * kijken voor valence arousal te mappen\n",
    " * kijken voor nog "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
