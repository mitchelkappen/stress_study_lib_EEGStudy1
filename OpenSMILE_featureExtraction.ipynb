{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction from Speech Data with OpenSMILE and GeMaps config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from io import StringIO\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, PowerTransformer, QuantileTransformer, Normalizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from joblib import dump, load\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import f_classif\n",
    "from joblib import dump, load\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Data Path\n",
    "DATA_PATH = \"C:/Users/mitch/OneDrive - UGent/UGent/Projects/5. VOP project/Voice_and_App/\"\n",
    "# Set OpenSMILE Config Path\n",
    "OPENSMILE_CONFIG = '\"C:/Users/mitch/OneDrive - UGent/UGent/Topics/Facial/OpenSmile/opensmile-2.3.0/config/gemaps/GeMAPSv01a.conf\"'\n",
    "\n",
    "FEATURES_PATH = DATA_PATH + \"features_emobase/\"\n",
    "STRESSED_PATH = FEATURES_PATH + \"stressed/\"\n",
    "UNSTRESSED_PATH = FEATURES_PATH + \"unstressed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only run this cell ONCE (set to False if exctracted)\n",
    "\n",
    "if False:\n",
    "    # Create paths if not existed\n",
    "    Path(STRESSED_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    Path(UNSTRESSED_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def extract(source, destination):\n",
    "        # Generate extraction command\n",
    "        cmd = \"C:/Users/mitch/OneDrive/Documents/UGent/Topics/Facial/OpenSmile/opensmile-2.3.0/SMILExtract_Release -C {} -I {} -O {}\".format(OPENSMILE_CONFIG, source, destination)\n",
    "    #     print(cmd)\n",
    "        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "        p.wait()\n",
    "\n",
    "    for wav_file in glob.glob(DATA_PATH + \"*/*.wav\"):\n",
    "        participant_dir = wav_file.split(\"/\")[-1]\n",
    "        participant_dir = participant_dir.split(\"\\\\\")[1]\n",
    "        name = os.path.basename(wav_file).split(\".\")[0]\n",
    "\n",
    "        if name == \"stressed\": # Post measures\n",
    "            path = STRESSED_PATH\n",
    "        elif name == \"unstressed\": # Pre measures\n",
    "            path = UNSTRESSED_PATH\n",
    "\n",
    "        out_path = path + name + \"_\" + participant_dir + \".arff\"\n",
    "\n",
    "        wav_file = '\"' + wav_file.replace(os.sep, '/') + '\"'\n",
    "        out_path = '\"' + out_path + '\"'\n",
    "\n",
    "        extract(wav_file, out_path)\n",
    "#         break\n",
    "        \n",
    "    print(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arff_to_dataframe(path):\n",
    "    did = os.path.basename(path).split('_')[-1].split('.')[0]\n",
    "    arff_content = open(path, \"r\").read()\n",
    "    \n",
    "    # scipy ARFF implementation doesn't support non-numeric attributes so remove them (aren't informative anyways)...\n",
    "    # This is just a string replace, a little hacky, should probably look for a better ARFF library\n",
    "    arff_content = arff_content.replace(\"'noname',\", \"\").replace(\"@attribute name string\", \"\").replace(\"'liveturn_0',\", \"\").replace(\",unassigned\", \"\").replace(\"@attribute class numeric\", \"\").replace(\"@attribute emotion unknown\", \"\").replace(\",?\", \"\").replace(\"'unknown',\", \"\")\n",
    "    f = StringIO(arff_content)\n",
    "    data = arff.loadarff(f)\n",
    "    data = pd.DataFrame(data[0])\n",
    "    data[\"id\"] = did\n",
    "    data[\"file\"] = os.path.basename(stressed_file)\n",
    "    if data.shape[0] > 1:\n",
    "        data.drop(data.index[1], inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed_datas = [] # stressed speech placeholder dataframe\n",
    "unstressed_datas = [] # unstressed speech placeholder dataframe\n",
    "\n",
    "for stressed_file in glob.glob(STRESSED_PATH + \"*.arff\"):\n",
    "    data = arff_to_dataframe(stressed_file)\n",
    "    stressed_datas.append(data)\n",
    "\n",
    "for unstressed_file in glob.glob(UNSTRESSED_PATH + \"*.arff\"):\n",
    "    data = arff_to_dataframe(unstressed_file)\n",
    "    unstressed_datas.append(data)\n",
    "\n",
    "stressed = pd.concat(stressed_datas)\n",
    "unstressed = pd.concat(unstressed_datas)\n",
    "\n",
    "stressed['stressed'] = 1\n",
    "unstressed['stressed'] = 0\n",
    "stressed[\"id\"] = stressed[\"id\"].astype(int)\n",
    "unstressed[\"id\"] = unstressed[\"id\"].astype(int)\n",
    "        \n",
    "data = pd.concat([unstressed, stressed])\n",
    "data = data.sort_values(['id', 'stressed'], ascending=[1, 0]).reset_index(drop=True)\n",
    "data = data.drop(data[data.stressed == -1].index)\n",
    "\n",
    "ids = data.pop('id')\n",
    "files = data.pop('file')\n",
    "labels = data.pop('stressed').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['F1F2Ratio'] = data['F1frequency_sma3nz_amean']/data['F2frequency_sma3nz_amean'] # Compute F1/F2 Ratio\n",
    "\n",
    "cleanData = pd.DataFrame(data[['F0semitoneFrom27.5Hz_sma3nz_amean','jitterLocal_sma3nz_amean','F1F2Ratio','HNRdBACF_sma3nz_amean','MeanVoicedSegmentLengthSec','VoicedSegmentsPerSec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up based on rows (starting with pre (rows are intermittent pre-post-pre-post - so duos per participant))\n",
    "maxX = len(cleanData)\n",
    "count = 0\n",
    "dataPre = []\n",
    "dataPost = []\n",
    "temp = []\n",
    "idPre = []\n",
    "idPost = []\n",
    "\n",
    "while count < maxX:\n",
    "    count = count +1\n",
    "    if count % 2 == 0:\n",
    "        dataPost.append(cleanData.iloc[count-1])\n",
    "        idPost.append(ids[count-1]) # create seperate column with actual participant no.\n",
    "    else:\n",
    "        dataPre.append(cleanData.iloc[count-1])\n",
    "        idPre.append(ids[count-1]) # create seperate column with actual participant no.\n",
    "    \n",
    "dataPre = pd.DataFrame(dataPre)\n",
    "dataPost = pd.DataFrame(dataPost)\n",
    "\n",
    "dataPre.insert (0, \"ID\", idPre)\n",
    "dataPost.insert (0, \"ID\", idPost)\n",
    "\n",
    "dataPre.reset_index(inplace = True) \n",
    "dataPost.reset_index(inplace = True) \n",
    "\n",
    "dataPre.to_csv(\"../../Data/geMapsFeatures_pre.csv\", index=False)\n",
    "dataPost.to_csv(\"../../Data/geMapsFeatures_post.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all columns for both variables to rename variables to PRE and POST\n",
    "# Simultaneously computing Delta scores\n",
    "maxX = len(dataPre.columns)\n",
    "dataDelta = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "while count < maxX:\n",
    "    if count > 1: # Skip IDs\n",
    "        dataDelta['Delta_' + dataPre.columns[count]] = dataPost.iloc[:,count]-dataPre.iloc[:,count]\n",
    "        dataPre.rename(columns={dataPre.columns[count]: 'PRE_' + dataPre.columns[count]}, inplace=True)\n",
    "        dataPost.rename(columns={dataPost.columns[count]: 'POST_' + dataPost.columns[count]}, inplace=True)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put pre- and post- together in one complete file\n",
    "dataPrePost = pd.concat([dataPre, dataPost, dataDelta], axis=1) # Concatting side-by-side pre and post data\n",
    "\n",
    "dataPrePost.to_csv(\"../../Data/speechFeatures_geMaps_PrePostDelta.csv\", index=False) # Writing to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge voice feature data with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other data - questionnaires - mood - demographics - EDA\n",
    "# otherData = pd.read_csv(\"C:\\\\Users\\\\mitch\\\\OneDrive - UGent\\\\UGent\\\\Projects\\\\5. VOP project\\\\Paper\\\\Submissions\\\\Main folder\\\\Upload\\\\Data\\\\Data.csv\")\n",
    "otherData = pd.read_csv(\n",
    "    \"C:/Users/mitch/OneDrive - UGent/UGent/Projects/5. VOP project/Paper/Submissions/Main folder/Upload/Data/dataKristof.csv\",\n",
    "    sep=\";\")\n",
    "\n",
    "df1 = pd.DataFrame(otherData[['ID','AGE','GENDER','KNOWS_EXPERIMENT_GOAL','RIGHTHANDED']])\n",
    "\n",
    "df2 = otherData.filter(regex='DASS')\n",
    "df2 = df2.stack().str.replace(',','.').unstack()\n",
    "df2 = df2.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df3 = otherData.filter(regex='RRS')\n",
    "df3 = df3.stack().str.replace(',','.').unstack()\n",
    "df3 = df3.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df4 = otherData.filter(regex='SCL')\n",
    "df4 = df4.stack().str.replace(',','.').unstack()\n",
    "df4 = df4.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df5 = pd.DataFrame(otherData[['Affect2','Affect3']])\n",
    "df5 = df5.stack().str.replace(',','.').unstack()\n",
    "df5 = df5.apply(pd.to_numeric, errors='coerce')\n",
    "df5 = df5.rename(columns={\"Affect2\": \"MoodPre\", \"Affect3\": \"MoodPost\"})\n",
    "df5[\"VAS_StressReactivity\"] = df5[\"MoodPost\"]-df5[\"MoodPre\"]\n",
    "\n",
    "df6 = pd.DataFrame(otherData[['NA2','NA3']])\n",
    "df6 = df6.stack().str.replace(',','.').unstack()\n",
    "df6 = df6.apply(pd.to_numeric, errors='coerce')\n",
    "df6 = df6.rename(columns={\"NA2\": \"NegAffPre\", \"NA3\": \"NegAffPost\"})\n",
    "df6[\"NA_Reactivity\"] = df6[\"NegAffPost\"]-df6[\"NegAffPre\"]\n",
    "\n",
    "\n",
    "df7 = pd.DataFrame(otherData[['MOE2','KRACHTIG2','BOOS2','TEVREDEN2','GESPANNEN2','NEERSLACHTIG2','PRETTIG2',\n",
    " 'MOE3','KRACHTIG3','BOOS3','TEVREDEN3','GESPANNEN3','NEERSLACHTIG3','PRETTIG3']])\n",
    "df7 = df7.rename(columns={'MOE2':'MOE1','KRACHTIG2':'KRACHTIG1','BOOS2':'BOOS1','TEVREDEN2':'TEVREDEN1','GESPANNEN2':'GESPANNEN1','NEERSLACHTIG2':'NEERSLACHTIG1','PRETTIG2':'PRETTIG1',\n",
    " 'MOE3':'MOE2','KRACHTIG3':'KRACHTIG2','BOOS3':'BOOS2','TEVREDEN3':'TEVREDEN2','GESPANNEN3':'GESPANNEN2','NEERSLACHTIG3':'NEERSLACHTIG2','PRETTIG3':'PRETTIG2'})\n",
    "\n",
    "\n",
    "# relevantData = [df1, df2, df3]\n",
    "# relevantData = pd.concat(relevantData)\n",
    "# print(pd.DataFrame(df2).head(140))\n",
    "joe = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis=1, sort=False)\n",
    "joe['ID'] = joe['ID'].apply(pd.to_numeric, errors='coerce')\n",
    "joe = joe.rename(columns={'ID':'IDS'})\n",
    "joe.to_csv(\"../../Data/DataSeg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load other data - questionnaires - mood - demographics - EDA\n",
    "# otherData = pd.read_csv(\"C:\\\\Users\\\\mitch\\\\OneDrive - UGent\\\\UGent\\\\Projects\\\\5. VOP project\\\\Paper\\\\Submissions\\\\Main folder\\\\Upload\\\\Data\\\\Data.csv\")\n",
    "\n",
    "otherData = pd.read_csv(\"../../Data/DataSeg.csv\")\n",
    "otherData = otherData.drop([148], axis=0) # Delete last row because something strange happening here when loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataComplete = pd.concat([otherData, dataPrePost], axis=1) # Merging all data together in one dataframe\n",
    "dataComplete.columns = map(str.upper, dataComplete.columns) # Capitalize column names\n",
    "\n",
    "dataComplete.to_csv(\"../../Data/completeData.csv\", index=False) # Writing to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>KNOWS_EXPERIMENT_GOAL</th>\n",
       "      <th>RIGHTHANDED</th>\n",
       "      <th>DASS1</th>\n",
       "      <th>DASS2</th>\n",
       "      <th>DASS3</th>\n",
       "      <th>DASS5</th>\n",
       "      <th>DASS6</th>\n",
       "      <th>...</th>\n",
       "      <th>GESPANNEN1</th>\n",
       "      <th>NEERSLACHTIG1</th>\n",
       "      <th>PRETTIG1</th>\n",
       "      <th>MOE2</th>\n",
       "      <th>KRACHTIG2</th>\n",
       "      <th>BOOS2</th>\n",
       "      <th>TEVREDEN2</th>\n",
       "      <th>GESPANNEN2</th>\n",
       "      <th>NEERSLACHTIG2</th>\n",
       "      <th>PRETTIG2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Vrouw</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>154.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Man</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>155.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>156.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>157.0</td>\n",
       "      <td>36</td>\n",
       "      <td>Vrouw</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>158.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Man</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID AGE GENDER KNOWS_EXPERIMENT_GOAL RIGHTHANDED  DASS1  DASS2  DASS3  \\\n",
       "0      2.0  22  Vrouw                 FALSE        TRUE    2.0    1.0    1.0   \n",
       "1      3.0  19    Man                 FALSE        TRUE    1.0    1.0    0.0   \n",
       "2      4.0  27    Man                 FALSE        TRUE    0.0    2.0    0.0   \n",
       "3      5.0  21    Man                 FALSE        TRUE    1.0    3.0    2.0   \n",
       "4      6.0  23    Man                 FALSE        TRUE    1.0    2.0    1.0   \n",
       "..     ...  ..    ...                   ...         ...    ...    ...    ...   \n",
       "143  154.0  58    Man                  TRUE        TRUE    1.0    0.0    0.0   \n",
       "144  155.0  21    Man                 FALSE        TRUE    0.0    0.0    1.0   \n",
       "145  156.0  21    Man                 FALSE        TRUE    0.0    1.0    0.0   \n",
       "146  157.0  36  Vrouw                 FALSE        TRUE    0.0    0.0    0.0   \n",
       "147  158.0  22    Man                 FALSE        TRUE    1.0    1.0    1.0   \n",
       "\n",
       "     DASS5  DASS6  ...  GESPANNEN1  NEERSLACHTIG1  PRETTIG1  MOE2  KRACHTIG2  \\\n",
       "0      1.0    2.0  ...          71              5        35    47         40   \n",
       "1      1.0    2.0  ...          28              0        85    35         35   \n",
       "2      0.0    0.0  ...           8              1        63    44         23   \n",
       "3      1.0    0.0  ...          19             47        40    44         44   \n",
       "4      1.0    1.0  ...          24              0        72    33         36   \n",
       "..     ...    ...  ...         ...            ...       ...   ...        ...   \n",
       "143    0.0    0.0  ...           8              0        69    15         79   \n",
       "144    2.0    1.0  ...           8              6        78     9        100   \n",
       "145    0.0    0.0  ...           4              2        54     2          4   \n",
       "146    0.0    1.0  ...           4              0        79    55         65   \n",
       "147    0.0    1.0  ...          38             40        54    54         56   \n",
       "\n",
       "     BOOS2  TEVREDEN2  GESPANNEN2  NEERSLACHTIG2  PRETTIG2  \n",
       "0       17         48          54             15        37  \n",
       "1        0         72          50              0        49  \n",
       "2       11         54          42             10        52  \n",
       "3       40         61          28             40        53  \n",
       "4        0         53          35              0        62  \n",
       "..     ...        ...         ...            ...       ...  \n",
       "143      1         86          16              0        75  \n",
       "144     70         70          44             29        69  \n",
       "145      1         54          12              2        50  \n",
       "146      0         70          30              3        55  \n",
       "147     43         28          56             30        19  \n",
       "\n",
       "[148 rows x 77 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'AGE', 'GENDER', 'KNOWS_EXPERIMENT_GOAL', 'RIGHTHANDED', 'DASS1',\n",
       "       'DASS2', 'DASS3', 'DASS5', 'DASS6', 'DASS7', 'DASS8', 'DASS9', 'DASS10',\n",
       "       'DASS11', 'DASS12', 'DASS13', 'DASS14', 'DASS15', 'DASS16', 'DASS17',\n",
       "       'DASS18', 'DASS19', 'DASS20', 'DASS21', 'DASS4_IMPUTED', 'DASS_ANXIETY',\n",
       "       'DASS_DEPRESSION', 'DASS_STRESS', 'RRS1', 'RRS3', 'RRS4', 'RRS5',\n",
       "       'RRS6', 'RRS7', 'RRS8', 'RRS9', 'RRS10', 'RRS11', 'RRS12', 'RRS13',\n",
       "       'RRS14', 'RRS15', 'RRS16', 'RRS17', 'RRS18', 'RRS19', 'RRS23', 'RRS24',\n",
       "       'RRS25', 'RRS26', 'RRS_BROODING', 'RRS_REFLECTION',\n",
       "       'RRS_TREYNOR_TOTAAL', 'MEAN_SCL_PRE_LEFT', 'MEAN_SCL_STRESS_LEFT',\n",
       "       'MEAN_SCL_POST_LEFT', 'MEAN_SCL_PRE_RIGHT', 'MEAN_SCL_STRESS_RIGHT',\n",
       "       'MEAN_SCL_POST_RIGHT', 'MOODPRE', 'MOODPOST', 'VAS_STRESSREACTIVITY',\n",
       "       'MOE1', 'KRACHTIG1', 'BOOS1', 'TEVREDEN1', 'GESPANNEN1',\n",
       "       'NEERSLACHTIG1', 'PRETTIG1', 'MOE2', 'KRACHTIG2', 'BOOS2', 'TEVREDEN2',\n",
       "       'GESPANNEN2', 'NEERSLACHTIG2', 'PRETTIG2', 'INDEX', 'ID',\n",
       "       'PRE_F0SEMITONEFROM27.5HZ_SMA3NZ_AMEAN', 'PRE_JITTERLOCAL_SMA3NZ_AMEAN',\n",
       "       'PRE_F1F2RATIO', 'PRE_HNRDBACF_SMA3NZ_AMEAN',\n",
       "       'PRE_MEANVOICEDSEGMENTLENGTHSEC', 'INDEX', 'ID',\n",
       "       'POST_F0SEMITONEFROM27.5HZ_SMA3NZ_AMEAN',\n",
       "       'POST_JITTERLOCAL_SMA3NZ_AMEAN', 'POST_F1F2RATIO',\n",
       "       'POST_HNRDBACF_SMA3NZ_AMEAN', 'POST_MEANVOICEDSEGMENTLENGTHSEC',\n",
       "       'DELTA_F0SEMITONEFROM27.5HZ_SMA3NZ_AMEAN',\n",
       "       'DELTA_JITTERLOCAL_SMA3NZ_AMEAN', 'DELTA_F1F2RATIO',\n",
       "       'DELTA_HNRDBACF_SMA3NZ_AMEAN', 'DELTA_MEANVOICEDSEGMENTLENGTHSEC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataComplete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
