{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7505abc-b16c-45ae-851c-5a7dc8c88b7f",
   "metadata": {},
   "source": [
    "# Extract R-peaks from ECG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec46ded-8f3f-4ac2-a7f5-ff120e1bd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e6de63-648a-4034-8ee3-06a136860639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from speech_study.process_ecg import process_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f8a902-3b0d-4871-82a2-8660cea444c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure user\n",
    "user = \"jonas\"  # set this to mitchel\n",
    "\n",
    "if user.lower() == \"jonas\":\n",
    "    BASE_PATH = Path(\"/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/\")\n",
    "elif user.lower() == \"mitchel\":\n",
    "    BASE_PATH = Path(\"D:/Data/EEG_Study_1/\")\n",
    "DATA_PATH = BASE_PATH.joinpath(\"aligned_data\")\n",
    "\n",
    "eeg_feat_stat_dir = Path(DATA_PATH).joinpath(\"EEG1_study_feat_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe5a0e-0557-469d-8633-46e7961537ae",
   "metadata": {},
   "source": [
    "For more information about the ECG processing, look at [this python script](../speech_study/process_ecg.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df58e2-1b1f-4733-8f47-36123abd30c8",
   "metadata": {},
   "source": [
    "## Process the `edf_aligned` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8572aba-e61b-43a3-bb19-938f4f646aab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030da426afa64615ba0fae89b89868a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/63/edf_aligned/ecg_2020_03_11.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/17/edf_aligned/ecg_2020_02_10.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/54/edf_aligned/ecg_2020_03_04.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/69/edf_aligned/ecg_2020_07_07.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/34/edf_aligned/ecg_2020_02_20.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/68/edf_aligned/ecg_2020_07_06.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/53/edf_aligned/ecg_2020_03_04.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/22/edf_aligned/ecg_2020_02_12.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/23/edf_aligned/ecg_2020_02_13.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/64/edf_aligned/ecg_2020_07_01.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/49/edf_aligned/ecg_2020_03_02.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/70/edf_aligned/ecg_2020_07_07.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/42/edf_aligned/ecg_2020_02_26.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/48/edf_aligned/ecg_2020_03_02.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/74/edf_aligned/ecg_2020_07_16.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/66/edf_aligned/ecg_2020_07_02.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/55/edf_aligned/ecg_2020_03_06.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/40/edf_aligned/ecg_2020_02_25.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/72/edf_aligned/ecg_2020_07_14.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/31/edf_aligned/ecg_2020_02_19.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/71/edf_aligned/ecg_2020_07_13.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/33/edf_aligned/ecg_2020_02_20.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/35/edf_aligned/ecg_2020_02_20.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/77/edf_aligned/ecg_2020_08_20.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/56/edf_aligned/ecg_2020_03_09.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/39/edf_aligned/ecg_2020_02_24.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/46/edf_aligned/ecg_2020_02_28.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/79/edf_aligned/ecg_2020_08_24.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/83/edf_aligned/ecg_2020_09_18.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/32/edf_aligned/ecg_2020_02_19.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/41/edf_aligned/ecg_2020_02_26.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/19/edf_aligned/ecg_2020_02_11.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/26/edf_aligned/ecg_2020_02_14.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/51/edf_aligned/ecg_2020_03_03.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/75/edf_aligned/ecg_2020_07_28.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/59/edf_aligned/ecg_2020_03_10.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/27/edf_aligned/ecg_2020_02_17.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/73/edf_aligned/ecg_2020_07_14.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/50/edf_aligned/ecg_2020_03_03.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/78/edf_aligned/ecg_2020_08_21.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/58/edf_aligned/ecg_2020_03_09.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/36/edf_aligned/ecg_2020_02_21.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/67/edf_aligned/ecg_2020_07_06.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/28/edf_aligned/ecg_2020_02_17.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/57/edf_aligned/ecg_2020_03_09.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/60/edf_aligned/ecg_2020_03_10.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/81/edf_aligned/ecg_2020_09_17.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/29/edf_aligned/ecg_2020_02_17.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/38/edf_aligned/ecg_2020_02_24.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/18/edf_aligned/ecg_2020_02_11.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/16/edf_aligned/ecg_2020_02_10.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/44/edf_aligned/ecg_2020_02_27.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/65/edf_aligned/ecg_2020_07_02.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/30/edf_aligned/ecg_2020_02_18.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/43/edf_aligned/ecg_2020_02_26.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/80/edf_aligned/ecg_2020_09_16.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/21/edf_aligned/ecg_2020_02_12.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/76/edf_aligned/ecg_2020_07_28.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/82/edf_aligned/ecg_2020_09_17.parquet\n"
     ]
    }
   ],
   "source": [
    "# First, process the aligned EDF files\n",
    "for pqt in tqdm(list(BASE_PATH.rglob(\"*/edf_aligned/ecg*.parquet\"))):\n",
    "    print(pqt)\n",
    "\n",
    "    # Read & process the ECG file\n",
    "    df_parquet = (\n",
    "        pd.read_parquet(pqt)\n",
    "        .set_index(\"timestamp\", drop=True)\n",
    "        .rename(columns={\"ECG_Raw\": \"ECG\"})\n",
    "    )\n",
    "    df_rr = process_ecg(df_parquet[\"ECG\"])\n",
    "\n",
    "    # save the file in feat stat dir\n",
    "    eeg_feat_stat_dir_user = eeg_feat_stat_dir.joinpath(pqt.parent.parent.name)\n",
    "    if not eeg_feat_stat_dir_user.exists():\n",
    "        os.mkdir(eeg_feat_stat_dir_user)\n",
    "    df_rr.reset_index().to_parquet(\n",
    "        eeg_feat_stat_dir_user.joinpath(\n",
    "            f\"rr_intervals_{'_'.join(pqt.name.split('_')[-3:])}\"\n",
    "        ),\n",
    "        engine=\"fastparquet\",\n",
    "    )\n",
    "\n",
    "    # save the file in the same folder as the ECG_file resides within\n",
    "    df_rr.reset_index().to_parquet(\n",
    "        pqt.parent.joinpath(f\"rr_intervals_{'_'.join(pqt.name.split('_')[-3:])}\"),\n",
    "        engine=\"fastparquet\",\n",
    "    )\n",
    "\n",
    "del df_parquet, pqt, eeg_feat_stat_dir_user, df_rr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b69a29-1f04-4673-9075-12b06ec2f528",
   "metadata": {},
   "source": [
    "## Process the non-aligned EDF_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27eb532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348c9a0b8d5f4b699e1d95461eee57c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/4/edf/ecg_2020_01_27.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/13/edf/ecg_2020_02_04.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/20/edf/ecg_2020_02_12.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/11/edf/ecg_2020_02_03.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/37/edf/ecg_2020_02_21.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/8/edf/ecg_2020_01_31.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/9/edf/ecg_2020_01_31.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/15/edf/ecg_2020_02_06.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/14/edf/ecg_2020_02_05.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/10/edf/ecg_2020_02_03.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/6/edf/ecg_2020_01_28.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/5/edf/ecg_2020_01_28.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/52/edf/ecg_2020_03_04.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/7/edf/ecg_2020_01_30.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/61/edf/ecg_2020_03_11.parquet\n",
      "/users/jonvdrdo/jonas/data/aaa_contextaware/raw/uz_study/aligned_data/12/edf/ecg_2020_02_04.parquet\n"
     ]
    }
   ],
   "source": [
    "# First create list of the aligned parquet users\n",
    "aligned_pqt_users = []\n",
    "for pqt in BASE_PATH.rglob(\"*/edf_aligned/ecg*.parquet\"):\n",
    "    aligned_pqt_users.append(pqt.parent.parent.name)\n",
    "\n",
    "\n",
    "for pqt in tqdm(list(BASE_PATH.rglob(\"*/edf/ecg*.parquet\"))):\n",
    "    # As aligned data takes precedence over non-aligned data, We will only process\n",
    "    # non-aligned `edf`-files when we do not have an aligned equivalent\n",
    "    if pqt.parent.parent.name not in aligned_pqt_users:\n",
    "        print(pqt)\n",
    "\n",
    "        df_parquet = (\n",
    "            pd.read_parquet(pqt)\n",
    "            .set_index(\"timestamp\", drop=True)\n",
    "            .rename(columns={\"ECG_Raw\": \"ECG\"})\n",
    "        )\n",
    "        df_rr = process_ecg(df_parquet[\"ECG\"])\n",
    "\n",
    "        # save the file in feat_stat_dir\n",
    "        eeg_feat_stat_dir_user = eeg_feat_stat_dir.joinpath(pqt.parent.parent.name)\n",
    "        if not eeg_feat_stat_dir_user.exists():\n",
    "            os.mkdir(eeg_feat_stat_dir_user)\n",
    "        df_rr.reset_index().to_parquet(\n",
    "            eeg_feat_stat_dir_user.joinpath(\n",
    "                f\"rr_intervals_{'_'.join(pqt.name.split('_')[-3:])}\"\n",
    "            ),\n",
    "            engine=\"fastparquet\",\n",
    "        )\n",
    "\n",
    "        # save the file in the same folder as the ECG_file resides within\n",
    "        df_rr.reset_index().to_parquet(\n",
    "            pqt.parent.joinpath(f\"rr_intervals_{'_'.join(pqt.name.split('_')[-3:])}\"),\n",
    "            engine=\"fastparquet\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f92014-4ef0-41a2-a132-a5cd5ef91b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_peak_agreement</th>\n",
       "      <th>RR_interval_ms</th>\n",
       "      <th>HRV_ms</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-04 10:05:25.041000+01:00</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 10:05:25.843000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 10:05:26.695000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 10:05:27.582000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 10:05:28.435000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>-34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 11:27:41.591000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 11:27:42.318000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>-38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 11:27:43.029000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 11:27:43.751000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-04 11:27:44.441000+01:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>-32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6085 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  r_peak_agreement  RR_interval_ms  HRV_ms\n",
       "timestamp                                                                 \n",
       "2020-02-04 10:05:25.041000+01:00               0.1             NaN     NaN\n",
       "2020-02-04 10:05:25.843000+01:00               1.0             NaN     NaN\n",
       "2020-02-04 10:05:26.695000+01:00               1.0           852.0     NaN\n",
       "2020-02-04 10:05:27.582000+01:00               1.0           887.0    35.0\n",
       "2020-02-04 10:05:28.435000+01:00               1.0           853.0   -34.0\n",
       "...                                            ...             ...     ...\n",
       "2020-02-04 11:27:41.591000+01:00               1.0           765.0    50.0\n",
       "2020-02-04 11:27:42.318000+01:00               1.0           727.0   -38.0\n",
       "2020-02-04 11:27:43.029000+01:00               1.0           711.0   -16.0\n",
       "2020-02-04 11:27:43.751000+01:00               1.0           722.0    11.0\n",
       "2020-02-04 11:27:44.441000+01:00               1.0           690.0   -32.0\n",
       "\n",
       "[6085 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e8839f-4f85-432f-8f18-86fd4630ac8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from context_aware.interfaces.empatica import EMPATICA_CONFIG\n",
    "from context_aware.time_series_tools.processing.gsr.clean_gsr import clean_eda\n",
    "# -------------------------------- TIME SERIES --------------------------------\n",
    "from tsflex.chunking import chunk_data\n",
    "from tsflex.processing import SeriesPipeline, SeriesProcessor, dataframe_func\n",
    "from tsflex.processing.utils import process_chunks_multithreaded\n",
    "\n",
    "\n",
    "# ------------------------------ GSR PROCESSING ---------------------------------\n",
    "def clean_empatica_eda(\n",
    "    gsr_series: pd.Series,\n",
    "    valid_window: int = 3,\n",
    "    max_interpolate: int = 30,\n",
    "    min_valid_len: int = 5 * 60,\n",
    "    eda_sqi_smoothen_win_size_s: float = 4,\n",
    ") -> pd.DataFrame:\n",
    "    fs = EMPATICA_CONFIG.SENSOR_FREQUENCIES[\"gsr\"]\n",
    "\n",
    "    out = clean_eda(\n",
    "        gsr_series.to_frame(),\n",
    "        \"EDA\",\n",
    "        fs=fs,\n",
    "        valid_window=valid_window,\n",
    "        max_interpolate=max_interpolate,\n",
    "        min_valid_len=min_valid_len,\n",
    "    )\n",
    "\n",
    "    out[\"EDA_SQI_smoothened\"] = (\n",
    "        out[\"EDA_SQI\"]\n",
    "        .rolling(\n",
    "            int(fs * eda_sqi_smoothen_win_size_s + 1),  # center=True\n",
    "        )\n",
    "        .sum()\n",
    "        / (fs * eda_sqi_smoothen_win_size_s + 1)\n",
    "    )\n",
    "    # if SQI is 0 -> retain zero\n",
    "    out[\"EDA_SQI_smoothened\"] *= out[\"EDA_SQI\"].map(int)\n",
    "    return out\n",
    "\n",
    "\n",
    "def decompose_eda_empatica(df_cleaned: pd.Series, method=\"cvxEDA\") -> pd.DataFrame:\n",
    "    df_cleaned_ = df_cleaned.dropna()\n",
    "    if len(df_cleaned_):\n",
    "        sanitized_eda: pd.Series = nk.signal_sanitize(df_cleaned_)\n",
    "        return nk.eda_phasic(\n",
    "            sanitized_eda,\n",
    "            sampling_rate=EMPATICA_CONFIG.SENSOR_FREQUENCIES[\"gsr\"],\n",
    "            method=method,\n",
    "        ).set_index(df_cleaned_.index)\n",
    "    else:\n",
    "        print(\n",
    "            \"\\tcleaned shape: \",\n",
    "            df_cleaned.shape,\n",
    "            \"\\tcleaned dropna shape: \",\n",
    "            df_cleaned_.shape,\n",
    "            flush=True,\n",
    "        )\n",
    "        warnings.warn(\n",
    "            f\"no not-Nan data `decompose_eda_empatica` will return an \"\n",
    "            + \"empty dataframe\"\n",
    "        )\n",
    "        return pd.DataFrame(columns=[\"EDA_Phasic\", \"EDA_Tonic\"])\n",
    "    # TODO -> add slope features\n",
    "\n",
    "\n",
    "def find_peaks_empatica(df_phasic: pd.Series, method=\"neurokit\") -> pd.DataFrame:\n",
    "    # note -> GAMBOA2008 it's peaks seem to be exactly the same as neurokit!\n",
    "    df_phasic = df_phasic.dropna()\n",
    "    if not len(df_phasic):\n",
    "        warnings.warn(\"find_peaks_empatica -> `df_phasic` has no not-nan values!\")\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"SCR_RiseTime\",\n",
    "                f\"SCR_Peaks_{method}\",\n",
    "                \"SCR_RecoveryTime\",\n",
    "                \"SCR_Amplitude\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    peak_signal, _ = nk.eda_peaks(\n",
    "        df_phasic,\n",
    "        sampling_rate=EMPATICA_CONFIG.SENSOR_FREQUENCIES[\"gsr\"],\n",
    "        amplitude_min=0,  # TODO -> play more with this parameter\n",
    "        method=method,\n",
    "    )\n",
    "    return peak_signal.set_index(df_phasic.index).rename(\n",
    "        columns={\"SCR_Peaks\": f\"SCR_Peaks_{method}\"}\n",
    "    )\n",
    "\n",
    "\n",
    "@dataframe_func\n",
    "def remove_false_positives_acc(\n",
    "    df,\n",
    "    min_rise_time_s=1,\n",
    "    min_recovery_time_s=1,\n",
    "    max_rise_time_s=15,\n",
    "    max_recovery_time_s=7,\n",
    "    min_scr_amplitude=0.02,\n",
    "    scr_amplitude_ratio=0.03,\n",
    "    eda_sqi_smoothened_threshold=0.6,\n",
    "    max_acc_std=45,\n",
    ") -> pd.DataFrame:\n",
    "    assert min_rise_time_s < max_rise_time_s\n",
    "    assert min_recovery_time_s < max_recovery_time_s\n",
    "    acc_cols = [\"ACC_x\", \"ACC_y\", \"ACC_z\"]\n",
    "    scr_cols = [\n",
    "        \"SCR_RiseTime\",\n",
    "        \"SCR_Peaks_neurokit\",  # not that loosely coupled\n",
    "        \"SCR_RecoveryTime\",\n",
    "        \"SCR_Amplitude\",\n",
    "        # additional EDA metadata\n",
    "        \"EDA_Tonic\",\n",
    "        \"EDA_SQI_smoothened\",\n",
    "    ]\n",
    "\n",
    "    df_scr = df[scr_cols].dropna(how=\"all\").copy()\n",
    "    df_scr = df_scr.fillna(0)\n",
    "    if not len(df_scr):\n",
    "        warnings.warn(\"remove_false_positives_acc -> `df_scr` has no not-nan values!\")\n",
    "        return pd.DataFrame(columns=scr_cols).add_suffix(\"_reduced_acc\")\n",
    "\n",
    "    df_acc = df[acc_cols].dropna()\n",
    "    # calculate the std\n",
    "    win_duration_s = 1\n",
    "    win_size = win_duration_s * EMPATICA_CONFIG.SENSOR_FREQUENCIES[\"acc\"]\n",
    "    win_size += 1 if win_size % 2 == 0 else 0  # make sure if win_size is odd\n",
    "    fs_gsr = 4\n",
    "    df_acc_std = (\n",
    "        pd.concat(\n",
    "            [df_acc[col].rolling(win_size, center=True).std() for col in acc_cols],\n",
    "            axis=1,\n",
    "            keys=acc_cols,\n",
    "        )\n",
    "        .max(axis=1)\n",
    "        .rename(\"ACC_std\")\n",
    "        .resample(f\"{int(1000 // fs_gsr)}ms\")\n",
    "        .mean()\n",
    "        .rolling(2 * fs_gsr + 1, center=True)\n",
    "        .max()\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    df_scr = pd.merge_asof(\n",
    "        df_scr, df_acc_std, left_index=True, right_index=True, direction=\"nearest\"\n",
    "    )\n",
    "\n",
    "    df_scr.loc[df_scr[\"SCR_RiseTime\"] < min_rise_time_s, scr_cols] = 0\n",
    "    df_scr.loc[df_scr[\"SCR_RiseTime\"] > max_rise_time_s, scr_cols] = 0\n",
    "\n",
    "    # df_scr.loc[df_scr[\"SCR_RecoveryTime\"] < min_recovery_time_s, scr_cols] = 0\n",
    "    df_scr.loc[df_scr[\"SCR_RecoveryTime\"] > max_recovery_time_s, scr_cols] = 0\n",
    "\n",
    "    # additional acc & amplitude related processing (compared to vic's processing)\n",
    "    # 1. relative SCR_Amplitude processing\n",
    "    df_scr.loc[\n",
    "        df_scr[\"SCR_Amplitude\"]\n",
    "        < np.clip(\n",
    "            scr_amplitude_ratio * df_scr[\"EDA_Tonic\"],\n",
    "            a_min=min_scr_amplitude,\n",
    "            a_max=None,\n",
    "        ),\n",
    "        scr_cols,\n",
    "    ] = 0\n",
    "\n",
    "    # 2. Remove peaks detected near low EDA sqi data\n",
    "    df_scr.loc[\n",
    "        df_scr[\"EDA_SQI_smoothened\"] < eda_sqi_smoothened_threshold, scr_cols\n",
    "    ] = 0\n",
    "\n",
    "    df_scr.loc[df_scr[\"ACC_std\"] > max_acc_std, scr_cols] = 0\n",
    "    # todo -> do not add _reduce_acc suffix to the 'add_std_col'\n",
    "    return pd.concat(\n",
    "        [\n",
    "            df_scr.drop(\n",
    "                columns=[\"EDA_Tonic\", \"ACC_std\", \"EDA_SQI_smoothened\"]\n",
    "            ).add_suffix(\"_reduced_acc\"),\n",
    "            df_scr[\"ACC_std\"],\n",
    "        ],\n",
    "        axis=1,\n",
    "        ignore_index=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# -------------------------- The processing pipelines\n",
    "gsr_processing_pipeline = SeriesPipeline(\n",
    "    processors=[\n",
    "        SeriesProcessor(series_names=[\"EDA\"], function=clean_empatica_eda),\n",
    "        SeriesProcessor(\n",
    "            series_names=[\"EDA\"],\n",
    "            function=decompose_eda_empatica,\n",
    "        ),\n",
    "        SeriesProcessor(\n",
    "            series_names=[\"EDA_Phasic\"],\n",
    "            function=find_peaks_empatica,\n",
    "            # additional kwargs\n",
    "            method=\"neurokit\",\n",
    "        ),\n",
    "        SeriesProcessor(\n",
    "            series_names=tuple(\n",
    "                [\n",
    "                    \"SCR_RiseTime\",\n",
    "                    \"SCR_Peaks_neurokit\",\n",
    "                    \"SCR_RecoveryTime\",\n",
    "                    \"SCR_Amplitude\",\n",
    "                    \"EDA_Tonic\",\n",
    "                    \"EDA_SQI_smoothened\",\n",
    "                    \"ACC_x\",\n",
    "                    \"ACC_y\",\n",
    "                    \"ACC_z\",\n",
    "                ]\n",
    "            ),\n",
    "            function=remove_false_positives_acc,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ------------- PIPELINES WRAPPERS\n",
    "def process_gsr_pipeline(\n",
    "    data_dict: Dict[str, pd.DataFrame], multiprocessing=True, show_progress=True\n",
    ") -> pd.DataFrame:\n",
    "    if multiprocessing:\n",
    "        df_out_gsr = pd.concat(\n",
    "            process_chunks_multithreaded(\n",
    "                same_range_chunks_list=chunk_data(\n",
    "                    # only process a sub-chunk of the data dict\n",
    "                    data=[data_dict[k] for k in [\"gsr\", \"acc\"]],\n",
    "                    fs_dict=EMPATICA_CONFIG.SIGNAL_FREQUENCIES,\n",
    "                    chunk_range_margin_s=10,\n",
    "                    min_chunk_dur_s=60 * 5,\n",
    "                    max_chunk_dur_s=60 * 60,\n",
    "                    sub_chunk_overlap_s=60 * 5,\n",
    "                    verbose=False,\n",
    "                    copy=False,\n",
    "                ),\n",
    "                series_pipeline=gsr_processing_pipeline,\n",
    "                n_jobs=16,\n",
    "                show_progress=show_progress,\n",
    "                drop_keys=[\"ACC_x\", \"ACC_y\", \"ACC_z\"],\n",
    "                return_all_series=True,\n",
    "                return_df=True,\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        df_out_gsr = gsr_processing_pipeline.process(\n",
    "            data=list(data_dict.values()),\n",
    "            return_all_series=True,\n",
    "            return_df=True,\n",
    "            drop_keys=[\"ACC_x\", \"ACC_y\", \"ACC_z\"],\n",
    "        )\n",
    "\n",
    "    df_out_gsr = (\n",
    "        df_out_gsr.rename(columns={\"EDA\": \"EDA_Processed\"})\n",
    "        .dropna(axis=0, subset=[\"EDA_SQI_smoothened\"], how=\"all\")  # must be all, right?\n",
    "        .reset_index()\n",
    "        .drop_duplicates(subset=\"timestamp\", keep=\"first\")\n",
    "        .set_index(\"timestamp\", drop=True)\n",
    "        .sort_index()\n",
    "        # TODO -> fix `Na` investigation in `clean_eda`\n",
    "        .fillna(method=\"backfill\")\n",
    "    )\n",
    "\n",
    "    # note -> with real-not continuous data we will need to work on a gap-like basis ...\n",
    "    # assert pd.infer_freq(df_out_gsr.index) is not None\n",
    "    return df_out_gsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0109d3b0-5ce0-4573-80c2-de4464009119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776a0047c2b04651bf91382eb61edc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/raw/uz_study/aligned_data/45/empatica/acc_2020_02_27.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/45/gsr_processed_2020_02_27.parquet\n",
      "../../data/raw/uz_study/aligned_data/63/empatica/acc_2020_03_11.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/63/gsr_processed_2020_03_11.parquet\n",
      "../../data/raw/uz_study/aligned_data/17/empatica/acc_2020_02_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/17/gsr_processed_2020_02_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/54/empatica/acc_2020_03_04.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/54/gsr_processed_2020_03_04.parquet\n",
      "../../data/raw/uz_study/aligned_data/69/empatica/acc_2020_07_07.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/69/gsr_processed_2020_07_07.parquet\n",
      "../../data/raw/uz_study/aligned_data/34/empatica/acc_2020_02_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/34/gsr_processed_2020_02_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/68/empatica/acc_2020_07_06.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/68/gsr_processed_2020_07_06.parquet\n",
      "../../data/raw/uz_study/aligned_data/53/empatica/acc_2020_03_04.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/53/gsr_processed_2020_03_04.parquet\n",
      "../../data/raw/uz_study/aligned_data/22/empatica/acc_2020_02_12.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/22/gsr_processed_2020_02_12.parquet\n",
      "../../data/raw/uz_study/aligned_data/23/empatica/acc_2020_02_13.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/23/gsr_processed_2020_02_13.parquet\n",
      "../../data/raw/uz_study/aligned_data/64/empatica/acc_2020_07_01.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/64/gsr_processed_2020_07_01.parquet\n",
      "../../data/raw/uz_study/aligned_data/49/empatica/acc_2020_03_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/49/gsr_processed_2020_03_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/70/empatica/acc_2020_07_07.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/70/gsr_processed_2020_07_07.parquet\n",
      "../../data/raw/uz_study/aligned_data/20/empatica/acc_2020_02_12.parquet\n",
      "\tcleaned shape:  (21078,) \tcleaned dropna shape:  (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jonvdrdo/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/ipykernel_launcher.py:70: UserWarning: no not-Nan data `decompose_eda_empatica` will return an empty dataframe\n",
      "/users/jonvdrdo/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/ipykernel_launcher.py:80: UserWarning: find_peaks_empatica -> `df_phasic` has no not-nan values!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/20/gsr_processed_2020_02_12.parquet\n",
      "../../data/raw/uz_study/aligned_data/42/empatica/acc_2020_02_26.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/42/gsr_processed_2020_02_26.parquet\n",
      "../../data/raw/uz_study/aligned_data/48/empatica/acc_2020_03_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/48/gsr_processed_2020_03_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/74/empatica/acc_2020_07_16.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/74/gsr_processed_2020_07_16.parquet\n",
      "../../data/raw/uz_study/aligned_data/37/empatica/acc_2020_02_21.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/37/gsr_processed_2020_02_21.parquet\n",
      "../../data/raw/uz_study/aligned_data/66/empatica/acc_2020_07_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/66/gsr_processed_2020_07_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/55/empatica/acc_2020_03_06.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/55/gsr_processed_2020_03_06.parquet\n",
      "../../data/raw/uz_study/aligned_data/24/empatica/acc_2020_02_13.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/24/gsr_processed_2020_02_13.parquet\n",
      "../../data/raw/uz_study/aligned_data/40/empatica/acc_2020_02_25.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/40/gsr_processed_2020_02_25.parquet\n",
      "../../data/raw/uz_study/aligned_data/72/empatica/acc_2020_07_14.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/72/gsr_processed_2020_07_14.parquet\n",
      "../../data/raw/uz_study/aligned_data/31/empatica/acc_2020_02_19.parquet\n",
      "\tcleaned shape:  (23964,) \tcleaned dropna shape:  (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jonvdrdo/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/ipykernel_launcher.py:70: UserWarning: no not-Nan data `decompose_eda_empatica` will return an empty dataframe\n",
      "/users/jonvdrdo/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/ipykernel_launcher.py:80: UserWarning: find_peaks_empatica -> `df_phasic` has no not-nan values!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/31/gsr_processed_2020_02_19.parquet\n",
      "../../data/raw/uz_study/aligned_data/71/empatica/acc_2020_07_13.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/71/gsr_processed_2020_07_13.parquet\n",
      "../../data/raw/uz_study/aligned_data/33/empatica/acc_2020_02_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/33/gsr_processed_2020_02_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/35/empatica/acc_2020_02_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/35/gsr_processed_2020_02_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/77/empatica/acc_2020_08_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/77/gsr_processed_2020_08_20.parquet\n",
      "../../data/raw/uz_study/aligned_data/56/empatica/acc_2020_03_09.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/56/gsr_processed_2020_03_09.parquet\n",
      "../../data/raw/uz_study/aligned_data/39/empatica/acc_2020_02_24.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/39/gsr_processed_2020_02_24.parquet\n",
      "../../data/raw/uz_study/aligned_data/46/empatica/acc_2020_02_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/46/gsr_processed_2020_02_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/79/empatica/acc_2020_08_24.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/79/gsr_processed_2020_08_24.parquet\n",
      "../../data/raw/uz_study/aligned_data/83/empatica/acc_2020_09_18.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/83/gsr_processed_2020_09_18.parquet\n",
      "../../data/raw/uz_study/aligned_data/32/empatica/acc_2020_02_19.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/32/gsr_processed_2020_02_19.parquet\n",
      "../../data/raw/uz_study/aligned_data/41/empatica/acc_2020_02_26.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/41/gsr_processed_2020_02_26.parquet\n",
      "../../data/raw/uz_study/aligned_data/19/empatica/acc_2020_02_11.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/19/gsr_processed_2020_02_11.parquet\n",
      "../../data/raw/uz_study/aligned_data/26/empatica/acc_2020_02_14.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/26/gsr_processed_2020_02_14.parquet\n",
      "../../data/raw/uz_study/aligned_data/51/empatica/acc_2020_03_03.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/51/gsr_processed_2020_03_03.parquet\n",
      "../../data/raw/uz_study/aligned_data/75/empatica/acc_2020_07_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/75/gsr_processed_2020_07_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/59/empatica/acc_2020_03_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/59/gsr_processed_2020_03_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/27/empatica/acc_2020_02_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/27/gsr_processed_2020_02_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/73/empatica/acc_2020_07_14.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/73/gsr_processed_2020_07_14.parquet\n",
      "../../data/raw/uz_study/aligned_data/50/empatica/acc_2020_03_03.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/50/gsr_processed_2020_03_03.parquet\n",
      "../../data/raw/uz_study/aligned_data/47/empatica/acc_2020_02_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/47/gsr_processed_2020_02_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/78/empatica/acc_2020_08_21.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/78/gsr_processed_2020_08_21.parquet\n",
      "../../data/raw/uz_study/aligned_data/58/empatica/acc_2020_03_09.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/58/gsr_processed_2020_03_09.parquet\n",
      "../../data/raw/uz_study/aligned_data/36/empatica/acc_2020_02_21.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/36/gsr_processed_2020_02_21.parquet\n",
      "../../data/raw/uz_study/aligned_data/67/empatica/acc_2020_07_06.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/67/gsr_processed_2020_07_06.parquet\n",
      "../../data/raw/uz_study/aligned_data/28/empatica/acc_2020_02_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/28/gsr_processed_2020_02_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/52/empatica/acc_2020_03_04.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/52/gsr_processed_2020_03_04.parquet\n",
      "../../data/raw/uz_study/aligned_data/57/empatica/acc_2020_03_09.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/57/gsr_processed_2020_03_09.parquet\n",
      "../../data/raw/uz_study/aligned_data/60/empatica/acc_2020_03_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/60/gsr_processed_2020_03_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/81/empatica/acc_2020_09_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/81/gsr_processed_2020_09_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/29/empatica/acc_2020_02_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/29/gsr_processed_2020_02_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/38/empatica/acc_2020_02_24.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/38/gsr_processed_2020_02_24.parquet\n",
      "../../data/raw/uz_study/aligned_data/18/empatica/acc_2020_02_11.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/18/gsr_processed_2020_02_11.parquet\n",
      "../../data/raw/uz_study/aligned_data/16/empatica/acc_2020_02_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/16/gsr_processed_2020_02_10.parquet\n",
      "../../data/raw/uz_study/aligned_data/44/empatica/acc_2020_02_27.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/44/gsr_processed_2020_02_27.parquet\n",
      "../../data/raw/uz_study/aligned_data/65/empatica/acc_2020_07_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/65/gsr_processed_2020_07_02.parquet\n",
      "../../data/raw/uz_study/aligned_data/30/empatica/acc_2020_02_18.parquet\n",
      "\tcleaned shape:  (18060,) \tcleaned dropna shape:  (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jonvdrdo/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/ipykernel_launcher.py:70: UserWarning: no not-Nan data `decompose_eda_empatica` will return an empty dataframe\n",
      "/users/jonvdrdo/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/ipykernel_launcher.py:80: UserWarning: find_peaks_empatica -> `df_phasic` has no not-nan values!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/30/gsr_processed_2020_02_18.parquet\n",
      "../../data/raw/uz_study/aligned_data/43/empatica/acc_2020_02_26.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/43/gsr_processed_2020_02_26.parquet\n",
      "../../data/raw/uz_study/aligned_data/80/empatica/acc_2020_09_16.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/80/gsr_processed_2020_09_16.parquet\n",
      "../../data/raw/uz_study/aligned_data/21/empatica/acc_2020_02_12.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/21/gsr_processed_2020_02_12.parquet\n",
      "../../data/raw/uz_study/aligned_data/76/empatica/acc_2020_07_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/76/gsr_processed_2020_07_28.parquet\n",
      "../../data/raw/uz_study/aligned_data/82/empatica/acc_2020_09_17.parquet\n",
      "../../data/raw/uz_study/aligned_data/EEG1_study_feat_stats/82/gsr_processed_2020_09_17.parquet\n"
     ]
    }
   ],
   "source": [
    "for pqt in tqdm(list(aligned_data_dir.rglob(\"*/empatica/acc*.parquet\"))):\n",
    "    print(pqt)\n",
    "    df_acc = pd.read_parquet(pqt).set_index(\"timestamp\", drop=True)\n",
    "    df_gsr = pd.read_parquet(\n",
    "        pqt.parent.joinpath(f\"gsr_{'_'.join(pqt.name.split('_')[-3:])}\")\n",
    "    ).set_index(\"timestamp\", drop=True)\n",
    "\n",
    "    df_out_gsr = process_gsr_pipeline(\n",
    "        data_dict={\"acc\": df_acc, \"gsr\": df_gsr}, multiprocessing=False\n",
    "    )\n",
    "    eeg_feat_stat_dir_user = eeg_feat_stat_dir.joinpath(pqt.parent.parent.name)\n",
    "    if not eeg_feat_stat_dir_user.exists():\n",
    "        os.mkdir(eeg_feat_stat_dir_user)\n",
    "    print(\n",
    "        eeg_feat_stat_dir_user.joinpath(\n",
    "            f\"gsr_processed_{'_'.join(pqt.name.split('_')[-3:])}\"\n",
    "        )\n",
    "    )\n",
    "    df_out_gsr.reset_index().to_parquet(\n",
    "        eeg_feat_stat_dir_user.joinpath(\n",
    "            f\"gsr_processed_{'_'.join(pqt.name.split('_')[-3:])}\"\n",
    "        ),\n",
    "        engine=\"fastparquet\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4b643c-0cb4-489c-9b9f-bfd528a5dd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888ffe489e98487fb0da3831378b3f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pqt in tqdm(list(eeg_feat_stat_dir.rglob(\"*/predictions.parquet\"))):\n",
    "    print(pqt)\n",
    "    os.remove(pqt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-study",
   "language": "python",
   "name": "speech-study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
